{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "#matplotlib.rcParams['figure.figsize'] = (6, 4)\n",
    "\n",
    "# ignore pandas warnings\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import time\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "data = pd.read_csv('training_ultrasound.csv')\n",
    "\n",
    "# remove agedays > 0 ( we just only focus pre-birth measurements)\n",
    "data = data[data['AGEDAYS']<0]\n",
    "\n",
    "# drop rows with missing data in any of the 5 main columns\n",
    "ultrasound = ['HCIRCM', 'ABCIRCM', 'BPDCM', 'FEMURCM']\n",
    "target = 'BWT_40'\n",
    "data.dropna(subset=ultrasound+[target], inplace=True)\n",
    "\n",
    "# correct faulty data\n",
    "data.loc[data['STUDYID']==2, 'PARITY'] = data.loc[data['STUDYID']==2, 'PARITY'] + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# select basic vars\n",
    "df = data[ultrasound + ['GAGEDAYS', 'SEXN', 'PARITY', 'GRAVIDA'] + [target]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HCIRCM        0\n",
       "ABCIRCM       0\n",
       "BPDCM         0\n",
       "FEMURCM       0\n",
       "GAGEDAYS      0\n",
       "SEXN          0\n",
       "PARITY      101\n",
       "GRAVIDA     101\n",
       "BWT_40        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# there is missing data for parity and gravida: this happens for first pregnancy --> fill with 1s\n",
    "df.fillna(1, inplace=True)\n",
    "\n",
    "# replace sex values to 0 and 1\n",
    "df['SEXN'] = df['SEXN'].replace([1,2], [0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# aspect ratio: measure of the slenderness\n",
    "df['femur/abd'] = df['FEMURCM']/df['ABCIRCM']\n",
    "\n",
    "# excentricity of the cenithal snapshot of the head (similar to ellipse)\n",
    "df['head'] = df['HCIRCM'] / df['BPDCM']\n",
    "\n",
    "# proxy for head volume\n",
    "df['vol'] = (df['BPDCM'])**3\n",
    "\n",
    "# body as a cilinder of radius ABCIRCM and height FEMURCM\n",
    "df['cilinder'] =(df['ABCIRCM']**2)*df['FEMURCM']\n",
    "\n",
    "# full interaction term for the 4 measurements\n",
    "df['four'] = df['HCIRCM']*df['BPDCM']*df['ABCIRCM']*df['FEMURCM']\n",
    "\n",
    "# femur length scaled with time\n",
    "df['femur_temp'] = (df['FEMURCM']/df['GAGEDAYS'])\n",
    "\n",
    "# head-femur polynomial interaction term\n",
    "df['head*femur'] = df['head']*df['FEMURCM']\n",
    "\n",
    "# no of past pregancies\n",
    "df['past_gest'] = df['PARITY'] - df['GRAVIDA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# common models for sonographic fetal weight estimation use log of the weight\n",
    "df['BWT_40'] = np.log(1 + df['BWT_40'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe size: 7928,17\n"
     ]
    }
   ],
   "source": [
    "print('Dataframe size: %s,%s' % (df.shape[0],df.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sklearn imports\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from aux_fun import plot_learning_curve, plot_validation_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train/test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df to np arrays\n",
    "X = df.drop(target,axis=1).values\n",
    "\n",
    "Y = df[target].values\n",
    "\n",
    "# train-test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "xgb = XGBRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CV strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from aux_fun import report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params_grid = {\n",
    "    'max_depth': [8],\n",
    "    'subsample': np.arange(0.7,1.0,0.1),\n",
    "    'learning_rate': np.arange(0.02,0.1,0.01),\n",
    "    'n_estimators': np.arange(50,1000,200)\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(xgb, param_distributions=params_grid, n_iter=50, \n",
    "                                   n_jobs=-1, scoring='mean_absolute_error', cv=kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=KFold(n_splits=10, random_state=0, shuffle=False),\n",
       "          error_score='raise',\n",
       "          estimator=XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=1, gamma=0,\n",
       "       learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
       "       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=0, silent=True, subsample=1),\n",
       "          fit_params={}, iid=True, n_iter=50, n_jobs=-1,\n",
       "          param_distributions={'subsample': array([ 0.7,  0.8,  0.9,  1. ]), 'n_estimators': array([ 50, 250, 450, 650, 850]), 'learning_rate': array([ 0.02,  0.03,  0.04,  0.05,  0.06,  0.07,  0.08,  0.09]), 'max_depth': [8]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score=True, scoring='mean_absolute_error',\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: -0.050975 (std: 0.001572)\n",
      "Parameters: {'subsample': 0.89999999999999991, 'learning_rate': 0.069999999999999993, 'max_depth': 8, 'n_estimators': 850}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: -0.051037 (std: 0.001564)\n",
      "Parameters: {'subsample': 0.89999999999999991, 'learning_rate': 0.059999999999999998, 'max_depth': 8, 'n_estimators': 850}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: -0.051279 (std: 0.001560)\n",
      "Parameters: {'subsample': 0.89999999999999991, 'max_depth': 8, 'learning_rate': 0.049999999999999996, 'n_estimators': 650}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_params = random_search.cv_results_['params'][np.flatnonzero(random_search.cv_results_['rank_test_score'] == 1)[0]]\n",
    "report(random_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight error: 0.2172 +- 0.0140\n"
     ]
    }
   ],
   "source": [
    "scores = list()\n",
    "# evaluate model with best alpha given by CV\n",
    "xgb.set_params(**best_params)\n",
    "for train_k, test_k in kf.split(x_train):\n",
    "    xgb.fit(x_train[train_k],y_train[train_k])\n",
    "    w_true_k = np.exp(y_train[test_k]) - 1\n",
    "    w_pred_k = np.exp(xgb.predict(x_train[test_k])) - 1\n",
    "    scores.append(mean_absolute_error(w_true_k, w_pred_k))\n",
    "print('Weight error: %0.4f +- %0.4f' % (np.mean(scores),2*np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit whole train with best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=1, gamma=0,\n",
       "       learning_rate=0.069999999999999993, max_delta_step=0, max_depth=8,\n",
       "       min_child_weight=1, missing=None, n_estimators=850, nthread=-1,\n",
       "       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=0, silent=True,\n",
       "       subsample=0.89999999999999991)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test mean abs error:  0.210557249449\n",
      "Mean relative error: 0.0651\n"
     ]
    }
   ],
   "source": [
    "w_true = np.exp(y_test) - 1\n",
    "w_pred = np.exp(xgb.predict(x_test)) - 1\n",
    "abs_error = mean_absolute_error(w_true, w_pred)\n",
    "pct_error = abs_error / w_true\n",
    "print('Test mean abs error: ', abs_error)\n",
    "print('Mean relative error: %0.4f' % pct_error.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "438.4367208480835"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.time() - start"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
