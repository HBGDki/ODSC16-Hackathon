{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "# ignore pandas warnings\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "data = pd.read_csv('training_ultrasound.csv')\n",
    "\n",
    "# remove agedays > 0 ( we just only focus pre-birth measurements)\n",
    "data = data[data['AGEDAYS']<0]\n",
    "\n",
    "# drop rows with missing data in any of the 5 main columns\n",
    "ultrasound = ['HCIRCM', 'ABCIRCM', 'BPDCM', 'FEMURCM']\n",
    "aux_measure = ['GAGEDAYS', 'SEXN', 'PARITY', 'GRAVIDA']\n",
    "target = 'BWT_40'\n",
    "data.dropna(subset=ultrasound+[target], inplace=True)\n",
    "\n",
    "# correct faulty data\n",
    "data.loc[data['STUDYID']==2, 'PARITY'] = data.loc[data['STUDYID']==2, 'PARITY'] + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# select basic vars\n",
    "df = data[ultrasound + aux_measure + [target]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HCIRCM        0\n",
       "ABCIRCM       0\n",
       "BPDCM         0\n",
       "FEMURCM       0\n",
       "GAGEDAYS      0\n",
       "SEXN          0\n",
       "PARITY      101\n",
       "GRAVIDA     101\n",
       "BWT_40        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# there is missing data for parity and gravida: this happens for first pregnancy --> fill with 1s\n",
    "df.fillna(1, inplace=True)\n",
    "\n",
    "# replace sex values to 0 and 1\n",
    "df['SEXN'] = df['SEXN'].replace([1,2], [0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HCIRCM', 'ABCIRCM', 'BPDCM', 'FEMURCM']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ultrasound"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "length_ratios = list()\n",
    "for m in ultrasound:\n",
    "    for n in ultrasound:\n",
    "        if m != n:\n",
    "            col_name = '%s / %s' % (m,n)\n",
    "            length_ratios.append(col_name)\n",
    "            df[col_name] = df[m] / df[n]\n",
    "\n",
    "length_ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "length_ratios = ['HCIRCM / ABCIRCM', 'HCIRCM / BPDCM', 'HCIRCM / FEMURCM',\n",
    "                 'ABCIRCM / BPDCM', 'ABCIRCM / FEMURCM', \n",
    "                 'BPDCM / FEMURCM']\n",
    "for ratio in length_ratios:\n",
    "    df[ratio] = df[ratio.split(' ')[0]] / df[ratio.split(' ')[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HCIRCM / GAGEDAYS',\n",
       " 'ABCIRCM / GAGEDAYS',\n",
       " 'BPDCM / GAGEDAYS',\n",
       " 'FEMURCM / GAGEDAYS']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenght_time = list()\n",
    "for m in ultrasound:\n",
    "    col_name = '%s / GAGEDAYS' % m\n",
    "    lenght_time.append(col_name)\n",
    "    df[col_name] = df[m] / df['GAGEDAYS']\n",
    "\n",
    "lenght_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# no of past pregancies\n",
    "df['past_gest'] = df['PARITY'] - df['GRAVIDA']\n",
    "\n",
    "other_feat = ['past_gest'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# common models for sonographic fetal weight estimation use log of the weight\n",
    "df['BWT_40'] = np.log(1 + df['BWT_40'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe size: 7928,20\n"
     ]
    }
   ],
   "source": [
    "print('Dataframe size: %s,%s' % (df.shape[0],df.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sklearn imports\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# xgboost\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# custom 'library'\n",
    "from aux_fun import plot_learning_curve, plot_validation_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train/test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pf = PolynomialFeatures(degree=4)\n",
    "X_poly_ultrasounds = pf.fit_transform(df[ultrasound].values)\n",
    "X_aux_measure = df[aux_measure].values\n",
    "X_lenght_ratios = df[length_ratios].values\n",
    "X_lenght_time = df[lenght_time].values\n",
    "X_other_feat = df[other_feat].values\n",
    "\n",
    "X = np.concatenate((X_poly_ultrasounds,X_aux_measure,X_lenght_ratios,X_lenght_time,X_other_feat),axis=1)\n",
    "\n",
    "Y = df[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "poly_feat_names = [e.replace('x0','HCIRCM').replace('x1','ABCIRCM').replace('x2','BPDCM').replace('x3','FEMURCM')\n",
    "              for e in pf.get_feature_names()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_feat_names = pd.Series(poly_feat_names + aux_measure + length_ratios + lenght_time + other_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train-test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb = XGBRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CV using all features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from aux_fun import report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params_grid = {\n",
    "    'max_depth': [8],\n",
    "    'subsample': np.arange(0.7,1.0,0.1),\n",
    "    'learning_rate': np.arange(0.02,0.1,0.01),\n",
    "    'n_estimators': np.arange(50,1000,200)\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(xgb, param_distributions=params_grid, n_iter=10, \n",
    "                                   n_jobs=-1, scoring='mean_absolute_error', cv=kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=KFold(n_splits=10, random_state=None, shuffle=False),\n",
       "          error_score='raise',\n",
       "          estimator=XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=1, gamma=0,\n",
       "       learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
       "       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=0, silent=True, subsample=1),\n",
       "          fit_params={}, iid=True, n_iter=10, n_jobs=-1,\n",
       "          param_distributions={'learning_rate': array([ 0.02,  0.03,  0.04,  0.05,  0.06,  0.07,  0.08,  0.09]), 'n_estimators': array([ 50, 250, 450, 650, 850]), 'max_depth': [8], 'subsample': array([ 0.7,  0.8,  0.9,  1. ])},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score=True, scoring='mean_absolute_error',\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: -0.050690 (std: 0.001256)\n",
      "Parameters: {'learning_rate': 0.049999999999999996, 'n_estimators': 850, 'max_depth': 8, 'subsample': 0.79999999999999993}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: -0.051218 (std: 0.001230)\n",
      "Parameters: {'learning_rate': 0.069999999999999993, 'n_estimators': 450, 'max_depth': 8, 'subsample': 0.99999999999999989}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: -0.051220 (std: 0.001458)\n",
      "Parameters: {'learning_rate': 0.049999999999999996, 'n_estimators': 450, 'max_depth': 8, 'subsample': 0.99999999999999989}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_params = random_search.cv_results_['params'][np.flatnonzero(random_search.cv_results_['rank_test_score'] == 1)[0]]\n",
    "report(random_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight error: 0.2158 +- 0.0112\n"
     ]
    }
   ],
   "source": [
    "scores = list()\n",
    "# evaluate model with best alpha given by CV\n",
    "xgb.set_params(**best_params)\n",
    "for train_k, test_k in kf.split(x_train):\n",
    "    xgb.fit(x_train[train_k],y_train[train_k])\n",
    "    w_true_k = np.exp(y_train[test_k]) - 1\n",
    "    w_pred_k = np.exp(xgb.predict(x_train[test_k])) - 1\n",
    "    scores.append(mean_absolute_error(w_true_k, w_pred_k))\n",
    "print('Weight error: %0.4f +- %0.4f' % (np.mean(scores),2*np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=1, gamma=0,\n",
       "       learning_rate=0.049999999999999996, max_delta_step=0, max_depth=8,\n",
       "       min_child_weight=1, missing=None, n_estimators=850, nthread=-1,\n",
       "       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=0, silent=True,\n",
       "       subsample=0.79999999999999993)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test mean abs error:  0.208531020161\n",
      "Mean relative error: 0.0645\n"
     ]
    }
   ],
   "source": [
    "w_true = np.exp(y_test) - 1\n",
    "w_pred = np.exp(xgb.predict(x_test)) - 1\n",
    "abs_error = mean_absolute_error(w_true, w_pred)\n",
    "pct_error = abs_error / w_true\n",
    "print('Test mean abs error: ', abs_error)\n",
    "print('Mean relative error: %0.4f' % pct_error.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "441.4033088684082"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.time() - start"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
